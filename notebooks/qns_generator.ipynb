{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import sys\n",
    "from typing import Optional, TypedDict, cast\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from azure.identity.aio import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents.aio import SearchClient\n",
    "from azure.search.documents.models import (\n",
    "    QueryCaptionResult,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncAzureOpenAI\n",
    "from openai_messages_token_helper import build_messages, get_token_limit\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "from app.backend.approaches.prompts import general_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=r\"..\\.azure\\hhgai-dev-eastasia-002\\.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_SEARCH_SERVICE = os.environ[\"AZURE_SEARCH_SERVICE\"]\n",
    "AZURE_SEARCH_INDEX = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "OPENAI_HOST = os.getenv(\"OPENAI_HOST\", \"azure\")\n",
    "OPENAI_CHATGPT_MODEL = os.environ[\"AZURE_OPENAI_CHATGPT_MODEL\"]\n",
    "OPENAI_EMB_MODEL = os.getenv(\"AZURE_OPENAI_EMB_MODEL_NAME\", \"text-embedding-ada-002\")\n",
    "OPENAI_EMB_DIMENSIONS = int(os.getenv(\"AZURE_OPENAI_EMB_DIMENSIONS\", 1536))\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = (\n",
    "    os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\") if OPENAI_HOST.startswith(\"azure\") else None\n",
    ")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-03-01-preview\"\n",
    "AZURE_OPENAI_EMB_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMB_DEPLOYMENT\") if OPENAI_HOST.startswith(\"azure\") else None\n",
    "AZURE_OPENAI_CUSTOM_URL = os.getenv(\"AZURE_OPENAI_CUSTOM_URL\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n",
    "AZURE_USE_AUTHENTICATION = os.getenv(\"AZURE_USE_AUTHENTICATION\", \"\").lower() == \"true\"\n",
    "AZURE_ENFORCE_ACCESS_CONTROL = os.getenv(\"AZURE_ENFORCE_ACCESS_CONTROL\", \"\").lower() == \"true\"\n",
    "AZURE_ENABLE_GLOBAL_DOCUMENT_ACCESS = os.getenv(\"AZURE_ENABLE_GLOBAL_DOCUMENT_ACCESS\", \"\").lower() == \"true\"\n",
    "AZURE_ENABLE_UNAUTHENTICATED_ACCESS = os.getenv(\"AZURE_ENABLE_UNAUTHENTICATED_ACCESS\", \"\").lower() == \"true\"\n",
    "AZURE_SERVER_APP_ID = os.getenv(\"AZURE_SERVER_APP_ID\")\n",
    "AZURE_SERVER_APP_SECRET = os.getenv(\"AZURE_SERVER_APP_SECRET\")\n",
    "AZURE_CLIENT_APP_ID = os.getenv(\"AZURE_CLIENT_APP_ID\")\n",
    "AZURE_AUTH_TENANT_ID = os.getenv(\"AZURE_AUTH_TENANT_ID\", AZURE_TENANT_ID)\n",
    "\n",
    "AZURE_SEARCH_QUERY_LANGUAGE = os.getenv(\"AZURE_SEARCH_QUERY_LANGUAGE\", \"en-us\")\n",
    "AZURE_SEARCH_QUERY_SPELLER = os.getenv(\"AZURE_SEARCH_QUERY_SPELLER\", \"lexicon\")\n",
    "AZURE_SEARCH_SEMANTIC_RANKER = os.getenv(\"AZURE_SEARCH_SEMANTIC_RANKER\", \"free\").lower()\n",
    "\n",
    "CHATGPT_TOKEN_LIMIT = get_token_limit(OPENAI_CHATGPT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_credential = DefaultAzureCredential(exclude_shared_token_cache_credential=True)\n",
    "token_provider = get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
    "    index_name=AZURE_SEARCH_INDEX,\n",
    "    credential=azure_credential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SEARCH_MAX_RESULTS = 30\n",
    "TEMPERATURE_QNS = 0.3\n",
    "TEMPERATURE_ANS = 0.0\n",
    "SEED = 1234\n",
    "USE_TEXT_SEARCH = \"Hybrid\"\n",
    "USE_VECTOR_SEARCH = \"Hybrid\"\n",
    "USE_SEMANTIC_RANKER = True\n",
    "USE_SEMANTIC_CAPTIONS = False\n",
    "MINIMUM_SEARCH_SCORE = 0.0\n",
    "MINIMUM_RERANKER_SCORE = 0.0\n",
    "\n",
    "RESPONSE_TOKEN_LIMIT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    id: Optional[str]\n",
    "    parent_id: Optional[str]\n",
    "    title: Optional[str]\n",
    "    pr_name: Optional[str]\n",
    "    cover_image_url: Optional[str]\n",
    "    full_url: Optional[str]\n",
    "    content_category: Optional[str]\n",
    "    chunks: Optional[str]\n",
    "    embedding: Optional[list[float]]\n",
    "    captions: list[QueryCaptionResult]\n",
    "    score: Optional[float] = None\n",
    "    reranker_score: Optional[float] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filter(filter_category):\n",
    "    filters = []\n",
    "    filters.append(\"content_category eq '{}'\".format(filter_category.replace(\"'\", \"''\")))\n",
    "    return None if len(filters) == 0 else \" and \".join(filters)\n",
    "\n",
    "\n",
    "def build_filter_article_search(id):\n",
    "    filters = []\n",
    "    id_content = f\"{id}_content\"\n",
    "    id_table = f\"{id}_table\"\n",
    "    filters.append(\"parent_id eq '{}'\".format(id_content.replace(\"'\", \"''\")))\n",
    "    filters.append(\"parent_id eq '{}'\".format(id_table.replace(\"'\", \"''\")))\n",
    "    return None if len(filters) == 0 else \" or \".join(filters)\n",
    "\n",
    "\n",
    "async def compute_text_embedding(q: str):\n",
    "    SUPPORTED_DIMENSIONS_MODEL = {\n",
    "        \"text-embedding-ada-002\": False,\n",
    "        \"text-embedding-3-small\": True,\n",
    "        \"text-embedding-3-large\": True,\n",
    "    }\n",
    "\n",
    "    class ExtraArgs(TypedDict, total=False):\n",
    "        dimensions: int\n",
    "\n",
    "    dimensions_args: ExtraArgs = (\n",
    "        {\"dimensions\": OPENAI_EMB_DIMENSIONS} if SUPPORTED_DIMENSIONS_MODEL[OPENAI_EMB_MODEL] else {}\n",
    "    )\n",
    "    embedding = await openai_client.embeddings.create(  # noqa: F704\n",
    "        # Azure OpenAI takes the deployment name as the model name\n",
    "        model=AZURE_OPENAI_EMB_DEPLOYMENT if AZURE_OPENAI_EMB_DEPLOYMENT else OPENAI_EMB_MODEL,\n",
    "        input=q,\n",
    "        **dimensions_args,\n",
    "    )\n",
    "    query_vector = embedding.data[0].embedding\n",
    "    return VectorizedQuery(vector=query_vector, k_nearest_neighbors=50, fields=\"embedding\")\n",
    "\n",
    "\n",
    "def get_citation(sourcepage: str, use_image_citation: bool) -> str:\n",
    "    if use_image_citation:\n",
    "        return sourcepage\n",
    "    else:\n",
    "        path, ext = os.path.splitext(sourcepage)\n",
    "        if ext.lower() == \".png\":\n",
    "            page_idx = path.rfind(\"-\")\n",
    "            page_number = int(path[page_idx + 1 :])\n",
    "            return f\"{path[:page_idx]}.pdf#page={page_number}\"\n",
    "\n",
    "        return sourcepage\n",
    "\n",
    "\n",
    "def nonewlines(s: str) -> str:\n",
    "    return s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "\n",
    "async def get_sources_content(\n",
    "    results: list[Document], use_semantic_captions: bool, use_image_citation: bool\n",
    ") -> list[str]:\n",
    "    if use_semantic_captions:\n",
    "        return [\n",
    "            {\n",
    "                \"id\": doc[\"id\"] or \"\",\n",
    "                \"article_id\": doc[\"parent_id\"] or \"\",\n",
    "                \"title\": doc[\"title\"] or \"\",\n",
    "                \"pr_name\": doc[\"pr_name\"] or \"\",\n",
    "                \"url\": get_citation((doc[\"full_url\"] or \"\"), use_image_citation),\n",
    "                \"chunk\": nonewlines(\" . \".join([cast(str, c.text) for c in (doc[\"captions\"] or [])])),\n",
    "            }\n",
    "            async for doc in results\n",
    "        ]\n",
    "    else:\n",
    "        return [\n",
    "            {\n",
    "                \"index_id\": doc[\"id\"] or \"\",\n",
    "                \"article_id\": doc[\"parent_id\"] or \"\",\n",
    "                \"title\": doc[\"title\"] or \"\",\n",
    "                \"pr_name\": doc[\"pr_name\"] or \"\",\n",
    "                \"url\": get_citation((doc[\"full_url\"] or \"\"), use_image_citation),\n",
    "                \"chunk\": nonewlines(doc[\"chunks\"] or \"\"),\n",
    "            }\n",
    "            async for doc in results\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_sources(sources_content, start_idx, end_idx):\n",
    "    combined = {\"index_ids\": [], \"article_ids\": [], \"titles\": [], \"pr_names\": [], \"urls\": [], \"chunks\": []}\n",
    "\n",
    "    for item in sources_content[start_idx:end_idx]:\n",
    "        combined[\"index_ids\"].append(item[\"index_id\"])\n",
    "        combined[\"article_ids\"].append(item[\"article_id\"])\n",
    "        combined[\"titles\"].append(item[\"title\"])\n",
    "        combined[\"pr_names\"].append(item[\"pr_name\"])\n",
    "        combined[\"urls\"].append(item[\"url\"])\n",
    "        combined[\"chunks\"].append(item[\"chunk\"])\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "def get_combined_sources(sources_content, step=5, total_combined=3):\n",
    "    combined_sources = []\n",
    "    for n in range(0, (total_combined + 1) * step, 5):\n",
    "        combined_source = concat_sources(sources_content, n, min(n + step, len(sources_content)))\n",
    "        combined_sources.append(combined_source)\n",
    "\n",
    "        # Stop when reach total_combined iterations\n",
    "        if len(combined_sources) >= total_combined:\n",
    "            break\n",
    "    return combined_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qns_generation_prompt = \"\"\"Your task is to formulate a set of 3 unique questions from given context, satisfying the rules given below:\n",
    "1. All generated questions should precisely pertain to the keywords {keyword}, and it is imperative that the topic is explicitly included as an integral part of each question.\n",
    "2. The generated questions should be straightforward, using simple language that is accessible to a broad audience. \n",
    "3. The generated questions should make sense to humans even when read without the given context.\n",
    "4. Prioritize clarity and brevity, ensuring that the questions are formulated in a way that reflect common language and would be easily comprehensible to the general public. \n",
    "5. Ensure that the questions generated are meaningful and relevant to the general public in understanding or exploring more about the given topic.\n",
    "7. Only generate questions that can be derived from the given context, including text and tables.\n",
    "8. Importantly, ensure uniqueness and non-repetition in the questions. \n",
    "9. Additionally, all questions must have answers found within the given context.\n",
    "10. Do not use phrases like 'provided context', etc in the generated questions.\n",
    "11. A generated question should contain less than 15 words.\n",
    "12. Use simple language in the questions generated that are accessible to a broad audience.\n",
    "13. Each question should be enclosed in ' '.\n",
    "14. Output as a list of questions separated by , and enclosed by [ ]. \n",
    "\n",
    "Example of output:\n",
    "['How can MediSave be used for outpatient treatments for newborns?', 'What are the MediSave withdrawal limits for assisted conception procedures?', 'How does MediShield Life help with payments for costly outpatient treatments?']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Generation by topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"content_category eq 'cost-and-financing'\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_category = \"cost-and-financing\"\n",
    "subpage = \"cost-and-financing\"\n",
    "filter = build_filter(content_category)\n",
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['medisave', 'medication', 'outpatient','medishield', 'treatments', 'payments', 'appointments']\",\n",
       " \"['disability', 'seniors', 'eldershield', 'rehabilitation', 'assistive', 'residential', 'eligibility', 'mobility', 'allowances']\",\n",
       " \"['insurance', 'insurers', 'medishield', ''coverage', 'cpf', 'mammograms', 'screening', 'mammogram', 'screen for life']\",\n",
       " \"['medifund', 'insurance', 'grants', 'fund', 'payments', 'needy', 'savings']\",\n",
       " \"['caregivers', 'caregiving', 'caregiver', 'grant', 'resident', 'disabilities', 'nursing homes']\",\n",
       " \"['merdeka generation cardholders', 'assessment fee', 'medishield life coverage', 'lasik prices', 'healthcare cost', 'regular health screenings', 'mammogram screenings', 'hpbs screening programmes', 'breast cancer screening', 'breast cancer screening subsidies']\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Topics by content category for Qns Generation.xlsx\", sheet_name=content_category)\n",
    "df_filtered = df[df[\"to_include\"] == \"yes\"]\n",
    "keywords_list = list(df_filtered[\"final keywords\"])\n",
    "keywords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qns_bank_path = \"question_bank.csv\"\n",
    "if os.path.exists(qns_bank_path):\n",
    "    # Read the CSV file into a DataFrame if it exists\n",
    "    df = pd.read_csv(qns_bank_path)\n",
    "else:\n",
    "    # Define an empty DataFrame if the file doesn't exist\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"content_category\",\n",
    "            \"subpage\",\n",
    "            \"keywords\",\n",
    "            \"source_num\",\n",
    "            \"index_ids\",\n",
    "            \"article_ids_unique\",\n",
    "            \"titles_unique\",\n",
    "            \"content_contributors\",\n",
    "            \"urls_unique\",\n",
    "            \"chunks\",\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keywords in keywords_list:\n",
    "    vectors: list[VectorQuery] = []\n",
    "    if USE_VECTOR_SEARCH:\n",
    "        vectors.append(await compute_text_embedding(keywords))  # noqa: F704\n",
    "\n",
    "    if USE_SEMANTIC_RANKER:\n",
    "        results = await search_client.search(  # noqa: F704\n",
    "            search_text=keywords,\n",
    "            filter=filter,\n",
    "            top=SEARCH_MAX_RESULTS,\n",
    "            query_caption=\"extractive|highlight-false\" if USE_SEMANTIC_CAPTIONS else None,\n",
    "            vector_queries=vectors,\n",
    "            query_type=QueryType.SEMANTIC,\n",
    "            query_language=AZURE_SEARCH_QUERY_LANGUAGE,\n",
    "            query_speller=AZURE_SEARCH_QUERY_SPELLER,\n",
    "            semantic_configuration_name=\"default\",\n",
    "            semantic_query=keywords,\n",
    "        )\n",
    "    else:\n",
    "        results = await search_client.search(  # noqa: F704\n",
    "            search_text=keywords,\n",
    "            filter=filter,\n",
    "            top=SEARCH_MAX_RESULTS,\n",
    "            vector_queries=vectors,\n",
    "        )\n",
    "\n",
    "    sources_content = await get_sources_content(results, USE_SEMANTIC_CAPTIONS, use_image_citation=False)  # noqa: F704\n",
    "    combined_sources = get_combined_sources(sources_content, step=5, total_combined=3)\n",
    "\n",
    "    for n in range(len(combined_sources)):\n",
    "        content = \"\\n\".join(combined_sources[n][\"chunks\"])\n",
    "\n",
    "        messages = build_messages(\n",
    "            model=OPENAI_CHATGPT_MODEL,\n",
    "            system_prompt=qns_generation_prompt.format(keyword=keywords),\n",
    "            new_user_content=f\"Please generate 3 unique questions on keywords '{keywords}' using the following provided source. \\n\\nSource:\\n {content}\",\n",
    "            max_tokens=CHATGPT_TOKEN_LIMIT - RESPONSE_TOKEN_LIMIT,\n",
    "        )\n",
    "        chat_coroutine = await openai_client.chat.completions.create(  # noqa: F704\n",
    "            # Azure OpenAI takes the deployment name as the model name\n",
    "            model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE_QNS,\n",
    "            max_tokens=RESPONSE_TOKEN_LIMIT,\n",
    "            n=1,\n",
    "            stream=False,\n",
    "            seed=SEED,\n",
    "        )\n",
    "\n",
    "        data = []\n",
    "        response_text_qns = chat_coroutine.choices[0].message.content\n",
    "        questions_list = ast.literal_eval(response_text_qns)\n",
    "        for question in questions_list:\n",
    "            messages_ans_generation = build_messages(\n",
    "                model=OPENAI_CHATGPT_MODEL,\n",
    "                system_prompt=general_prompt.format(language=\"ENGLISH\"),\n",
    "                new_user_content=question + \"\\n\\nSources:\\n\" + content,\n",
    "                max_tokens=CHATGPT_TOKEN_LIMIT - RESPONSE_TOKEN_LIMIT,\n",
    "            )\n",
    "            chat_coroutine = await openai_client.chat.completions.create(  # noqa: F704\n",
    "                # Azure OpenAI takes the deployment name as the model name\n",
    "                model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "                messages=messages_ans_generation,\n",
    "                temperature=TEMPERATURE_ANS,\n",
    "                max_tokens=RESPONSE_TOKEN_LIMIT,\n",
    "                n=1,\n",
    "                stream=False,\n",
    "                seed=SEED,\n",
    "            )\n",
    "\n",
    "            response_text_ans = chat_coroutine.choices[0].message.content\n",
    "            data.append(\n",
    "                {\n",
    "                    \"content_category\": content_category,\n",
    "                    \"subpage\": subpage,\n",
    "                    \"keywords\": keywords,\n",
    "                    \"source_num\": f\"source_{n+1}\",\n",
    "                    \"index_ids\": combined_sources[n][\"index_ids\"],\n",
    "                    \"article_ids_unique\": list(set(combined_sources[n][\"article_ids\"])),\n",
    "                    \"titles_unique\": list(set(combined_sources[n][\"titles\"])),\n",
    "                    \"content_contributors\": list(set(combined_sources[n][\"pr_names\"])),\n",
    "                    \"urls_unique\": list(set(combined_sources[n][\"urls\"])),\n",
    "                    \"chunks\": content,\n",
    "                    \"question\": question,\n",
    "                    \"answer\": response_text_ans,\n",
    "                }\n",
    "            )\n",
    "        df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_category</th>\n",
       "      <th>subpage</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source_num</th>\n",
       "      <th>index_ids</th>\n",
       "      <th>article_ids_unique</th>\n",
       "      <th>titles_unique</th>\n",
       "      <th>content_contributors</th>\n",
       "      <th>urls_unique</th>\n",
       "      <th>chunks</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cost-and-financing</td>\n",
       "      <td>cost-and-financing</td>\n",
       "      <td>['medisave', 'medication', 'outpatient','medis...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>[e096252aa674_1434993_content_content_pages_0,...</td>\n",
       "      <td>[1435063_content, 1435010_content, 1435032_con...</td>\n",
       "      <td>[​Costs and financing, MediSave Claims for Pol...</td>\n",
       "      <td>[National Healthcare Group, Khoo Teck Puat Hos...</td>\n",
       "      <td>[https://www.healthhub.sg/a-z/costs-and-financ...</td>\n",
       "      <td>What is MediSave? MediSave, introduced in Apri...</td>\n",
       "      <td>How can MediSave be used for outpatient treatm...</td>\n",
       "      <td>MediSave can be used for outpatient treatments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cost-and-financing</td>\n",
       "      <td>cost-and-financing</td>\n",
       "      <td>['medisave', 'medication', 'outpatient','medis...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>[e096252aa674_1434993_content_content_pages_0,...</td>\n",
       "      <td>[1435063_content, 1435010_content, 1435032_con...</td>\n",
       "      <td>[​Costs and financing, MediSave Claims for Pol...</td>\n",
       "      <td>[National Healthcare Group, Khoo Teck Puat Hos...</td>\n",
       "      <td>[https://www.healthhub.sg/a-z/costs-and-financ...</td>\n",
       "      <td>What is MediSave? MediSave, introduced in Apri...</td>\n",
       "      <td>What are the co-payment requirements for outpa...</td>\n",
       "      <td>For outpatient treatments under MediSave, ther...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     content_category             subpage  \\\n",
       "0  cost-and-financing  cost-and-financing   \n",
       "1  cost-and-financing  cost-and-financing   \n",
       "\n",
       "                                            keywords source_num  \\\n",
       "0  ['medisave', 'medication', 'outpatient','medis...   source_1   \n",
       "1  ['medisave', 'medication', 'outpatient','medis...   source_1   \n",
       "\n",
       "                                           index_ids  \\\n",
       "0  [e096252aa674_1434993_content_content_pages_0,...   \n",
       "1  [e096252aa674_1434993_content_content_pages_0,...   \n",
       "\n",
       "                                  article_ids_unique  \\\n",
       "0  [1435063_content, 1435010_content, 1435032_con...   \n",
       "1  [1435063_content, 1435010_content, 1435032_con...   \n",
       "\n",
       "                                       titles_unique  \\\n",
       "0  [​Costs and financing, MediSave Claims for Pol...   \n",
       "1  [​Costs and financing, MediSave Claims for Pol...   \n",
       "\n",
       "                                content_contributors  \\\n",
       "0  [National Healthcare Group, Khoo Teck Puat Hos...   \n",
       "1  [National Healthcare Group, Khoo Teck Puat Hos...   \n",
       "\n",
       "                                         urls_unique  \\\n",
       "0  [https://www.healthhub.sg/a-z/costs-and-financ...   \n",
       "1  [https://www.healthhub.sg/a-z/costs-and-financ...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  What is MediSave? MediSave, introduced in Apri...   \n",
       "1  What is MediSave? MediSave, introduced in Apri...   \n",
       "\n",
       "                                            question  \\\n",
       "0  How can MediSave be used for outpatient treatm...   \n",
       "1  What are the co-payment requirements for outpa...   \n",
       "\n",
       "                                              answer  \n",
       "0  MediSave can be used for outpatient treatments...  \n",
       "1  For outpatient treatments under MediSave, ther...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>source_num</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['caregivers', 'caregiving', 'caregiver', 'gra...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['caregivers', 'caregiving', 'caregiver', 'gra...</td>\n",
       "      <td>source_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['caregivers', 'caregiving', 'caregiver', 'gra...</td>\n",
       "      <td>source_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['disability', 'seniors', 'eldershield', 'reha...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['disability', 'seniors', 'eldershield', 'reha...</td>\n",
       "      <td>source_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['disability', 'seniors', 'eldershield', 'reha...</td>\n",
       "      <td>source_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['insurance', 'insurers', 'medishield', ''cove...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['insurance', 'insurers', 'medishield', ''cove...</td>\n",
       "      <td>source_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['insurance', 'insurers', 'medishield', ''cove...</td>\n",
       "      <td>source_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['medifund', 'insurance', 'grants', 'fund', 'p...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['medifund', 'insurance', 'grants', 'fund', 'p...</td>\n",
       "      <td>source_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['medifund', 'insurance', 'grants', 'fund', 'p...</td>\n",
       "      <td>source_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['medisave', 'medication', 'outpatient','medis...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['medisave', 'medication', 'outpatient','medis...</td>\n",
       "      <td>source_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['medisave', 'medication', 'outpatient','medis...</td>\n",
       "      <td>source_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['merdeka generation cardholders', 'assessment...</td>\n",
       "      <td>source_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['merdeka generation cardholders', 'assessment...</td>\n",
       "      <td>source_2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['merdeka generation cardholders', 'assessment...</td>\n",
       "      <td>source_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             keywords source_num  count\n",
       "0   ['caregivers', 'caregiving', 'caregiver', 'gra...   source_1      3\n",
       "1   ['caregivers', 'caregiving', 'caregiver', 'gra...   source_2      3\n",
       "2   ['caregivers', 'caregiving', 'caregiver', 'gra...   source_3      3\n",
       "3   ['disability', 'seniors', 'eldershield', 'reha...   source_1      3\n",
       "4   ['disability', 'seniors', 'eldershield', 'reha...   source_2      3\n",
       "5   ['disability', 'seniors', 'eldershield', 'reha...   source_3      3\n",
       "6   ['insurance', 'insurers', 'medishield', ''cove...   source_1      3\n",
       "7   ['insurance', 'insurers', 'medishield', ''cove...   source_2      3\n",
       "8   ['insurance', 'insurers', 'medishield', ''cove...   source_3      3\n",
       "9   ['medifund', 'insurance', 'grants', 'fund', 'p...   source_1      3\n",
       "10  ['medifund', 'insurance', 'grants', 'fund', 'p...   source_2      3\n",
       "11  ['medifund', 'insurance', 'grants', 'fund', 'p...   source_3      3\n",
       "12  ['medisave', 'medication', 'outpatient','medis...   source_1      3\n",
       "13  ['medisave', 'medication', 'outpatient','medis...   source_2      3\n",
       "14  ['medisave', 'medication', 'outpatient','medis...   source_3      3\n",
       "15  ['merdeka generation cardholders', 'assessment...   source_1      3\n",
       "16  ['merdeka generation cardholders', 'assessment...   source_2      3\n",
       "17  ['merdeka generation cardholders', 'assessment...   source_3      3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = df.groupby([\"keywords\", \"source_num\"]).size().reset_index(name=\"count\")\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of duplicate questions: 4\n",
      "No. of duplicate rows: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joycelyn\\AppData\\Local\\Temp\\ipykernel_26136\\1368191701.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_copy = df.applymap(lambda x: str(x) if isinstance(x, list) else x)\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.applymap(lambda x: str(x) if isinstance(x, list) else x)\n",
    "duplicate_qns = df_copy[df_copy.duplicated(subset=\"question\", keep=False)]\n",
    "duplicate_row = df_copy[df_copy.duplicated(keep=False)]\n",
    "print(f\"No. of duplicate questions: {len(duplicate_qns)}\")\n",
    "print(f\"No. of duplicate rows: {len(duplicate_row)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drop = df.drop_duplicates(subset='question')\n",
    "# df_drop.shape\n",
    "# df = df.drop_duplicates(subset='question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"questions_bank_{content_category}.csv\", index=False)\n",
    "# df.to_csv(f\"questions_bank.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Generation by articles\n",
    "Applicable to content_category: health-statistics, medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to shift up to parameters later\n",
    "SEARCH_MAX_RESULTS_ARTICLE = 10\n",
    "article_search_params = {\n",
    "    \"health-statistics\": {\"keywords\": [\"healthcare statistics\"], \"percentile\": 0.75},  # 4 out of 15 articles\n",
    "    \"medications\": {\n",
    "        \"keywords\": [\n",
    "            \"dosage\",\n",
    "            \"usage and adherence\",\n",
    "            \"drug safety\",\n",
    "            \"drug interaction\",\n",
    "            \"food interaction\",\n",
    "            \"side effects\",\n",
    "            \"storage\",\n",
    "            \"prescription\",\n",
    "            \"symptoms\",\n",
    "            \"purpose of drug\",\n",
    "            \"precaution\",\n",
    "        ],\n",
    "        \"percentile\": 0.90,  # 58 out of 579 articles\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 39)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_category = \"health-statistics\"\n",
    "df = pq.read_table(\"merged_data.parquet\")\n",
    "df = df.to_pandas()\n",
    "\n",
    "df_filtered = df[df[\"content_category\"] == content_category]\n",
    "remove_type_list = [\n",
    "    \"No Extracted Content\",\n",
    "    \"NaN\",\n",
    "    \"No relevant content and mainly links\",\n",
    "    \"Table of Contents\",\n",
    "    \"No HTML Tags\",\n",
    "]\n",
    "df_filtered = df_filtered[~df_filtered[\"remove_type\"].isin(remove_type_list)]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile value: 1279.5, Number of articles: 4\n"
     ]
    }
   ],
   "source": [
    "percentile_value = df_filtered[\"page_views\"].quantile(article_search_params[content_category][\"percentile\"])\n",
    "df_percentile = df_filtered[df_filtered[\"page_views\"] > percentile_value]\n",
    "print(f\"Percentile value: {percentile_value}, Number of articles: {df_percentile.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qns_bank_path = \"questions_bank.csv\"\n",
    "if os.path.exists(qns_bank_path):\n",
    "    # Read the CSV file into a DataFrame if it exists\n",
    "    df = pd.read_csv(qns_bank_path)\n",
    "else:\n",
    "    # Define an empty DataFrame if the file doesn't exist\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"content_category\",\n",
    "            \"subpage\",\n",
    "            \"keywords\",\n",
    "            \"source_num\",\n",
    "            \"index_ids\",\n",
    "            \"article_ids_unique\",\n",
    "            \"titles_unique\",\n",
    "            \"content_contributors\",\n",
    "            \"urls_unique\",\n",
    "            \"chunks\",\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437960 Admissions: Top 10 Reasons for Being Admitted to Hospital\n",
      "['healthcare statistics']\n",
      "parent_id eq '1437960_content' or parent_id eq '1437960_table'\n",
      "1437954 Principal Causes of Death\n",
      "['healthcare statistics']\n",
      "parent_id eq '1437954_content' or parent_id eq '1437954_table'\n",
      "1437958 Disease Burden Statistics for Singapore\n",
      "['healthcare statistics']\n",
      "parent_id eq '1437958_content' or parent_id eq '1437958_table'\n",
      "1437942 Healthcare Workforce Statistics\n",
      "['healthcare statistics']\n",
      "parent_id eq '1437942_content' or parent_id eq '1437942_table'\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for index, row in df_percentile.iterrows():\n",
    "    title = row[\"title\"]\n",
    "    id = row[\"id\"]\n",
    "    keywords = article_search_params[content_category][\"keywords\"]\n",
    "    filter = build_filter_article_search(id)\n",
    "\n",
    "    vectors: list[VectorQuery] = []\n",
    "    if USE_VECTOR_SEARCH:\n",
    "        vectors.append(await compute_text_embedding(keywords))  # noqa: F704\n",
    "\n",
    "    if USE_SEMANTIC_RANKER:\n",
    "        results = await search_client.search(  # noqa: F704\n",
    "            search_text=keywords,\n",
    "            filter=filter,\n",
    "            top=SEARCH_MAX_RESULTS_ARTICLE,\n",
    "            query_caption=\"extractive|highlight-false\" if USE_SEMANTIC_CAPTIONS else None,\n",
    "            vector_queries=vectors,\n",
    "            query_type=QueryType.SEMANTIC,\n",
    "            query_language=AZURE_SEARCH_QUERY_LANGUAGE,\n",
    "            query_speller=AZURE_SEARCH_QUERY_SPELLER,\n",
    "            semantic_configuration_name=\"default\",\n",
    "            semantic_query=keywords,\n",
    "        )\n",
    "    else:\n",
    "        results = await search_client.search(  # noqa: F704\n",
    "            search_text=keywords,\n",
    "            filter=filter,\n",
    "            top=SEARCH_MAX_RESULTS_ARTICLE,\n",
    "            vector_queries=vectors,\n",
    "        )\n",
    "\n",
    "    sources_content = await get_sources_content(results, USE_SEMANTIC_CAPTIONS, use_image_citation=False)  # noqa: F704\n",
    "    combined = concat_sources(sources_content, 0, len(sources_content))\n",
    "    content = \"\\n\".join(combined[\"chunks\"])\n",
    "\n",
    "    messages = build_messages(\n",
    "        model=OPENAI_CHATGPT_MODEL,\n",
    "        system_prompt=qns_generation_prompt.format(keyword=keywords),\n",
    "        new_user_content=f\"Please generate 3 unique questions on keywords '{keywords}' using the following provided source. \\n\\nSource:\\n {content}\",\n",
    "        max_tokens=CHATGPT_TOKEN_LIMIT - RESPONSE_TOKEN_LIMIT,\n",
    "    )\n",
    "\n",
    "    chat_coroutine = await openai_client.chat.completions.create(  # noqa: F704\n",
    "        # Azure OpenAI takes the deployment name as the model name\n",
    "        model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE_QNS,\n",
    "        max_tokens=RESPONSE_TOKEN_LIMIT,\n",
    "        n=1,\n",
    "        stream=False,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    response_text_qns = chat_coroutine.choices[0].message.content\n",
    "    questions_list = ast.literal_eval(response_text_qns)\n",
    "    data = []\n",
    "    for question in questions_list:\n",
    "        messages_ans_generation = build_messages(\n",
    "            model=OPENAI_CHATGPT_MODEL,\n",
    "            system_prompt=general_prompt.format(language=\"ENGLISH\"),\n",
    "            new_user_content=question + \"\\n\\nSources:\\n\" + content,\n",
    "            max_tokens=CHATGPT_TOKEN_LIMIT - RESPONSE_TOKEN_LIMIT,\n",
    "        )\n",
    "        chat_coroutine = await openai_client.chat.completions.create(  # noqa: F704\n",
    "            # Azure OpenAI takes the deployment name as the model name\n",
    "            model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "            messages=messages_ans_generation,\n",
    "            temperature=TEMPERATURE_ANS,\n",
    "            max_tokens=RESPONSE_TOKEN_LIMIT,\n",
    "            n=1,\n",
    "            stream=False,\n",
    "            seed=SEED,\n",
    "        )\n",
    "        response_text_ans = chat_coroutine.choices[0].message.content\n",
    "        data.append(\n",
    "            {\n",
    "                \"content_category\": content_category,\n",
    "                \"subpage\": \"\",\n",
    "                \"keywords\": \"\",\n",
    "                \"source_num\": f\"source_{cnt}\",\n",
    "                \"index_ids\": list(set(combined[\"index_ids\"])),\n",
    "                \"article_ids_unique\": list(set(combined[\"article_ids\"])),\n",
    "                \"titles_unique\": list(set(combined[\"titles\"])),\n",
    "                \"content_contributors\": list(set(combined[\"pr_names\"])),\n",
    "                \"urls_unique\": list(set(combined[\"urls\"])),\n",
    "                \"chunks\": content,\n",
    "                \"question\": question,\n",
    "                \"answer\": response_text_ans,\n",
    "            }\n",
    "        )\n",
    "    df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"questions_bank.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-hh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
