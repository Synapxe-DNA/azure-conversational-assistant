{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file is used for the testing of the data processing for a few articles instead of the whole parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions before running all the cells:\n",
    "1. Change the input directory to the path that you stored the \"merged_data_rag.parquet\" and the respective output directory to your intended output folders\n",
    "2. Install the required packages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cli in ./.venv/lib/python3.11/site-packages (2.63.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime~=4.13.1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.13.2)\n",
      "Requirement already satisfied: azure-appconfiguration~=1.1.1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.1.1)\n",
      "Requirement already satisfied: azure-batch~=14.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (14.2.0)\n",
      "Requirement already satisfied: azure-cli-core==2.63.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.63.0)\n",
      "Requirement already satisfied: azure-cosmos>=3.0.2,~=3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (3.2.0)\n",
      "Requirement already satisfied: azure-data-tables==12.4.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (12.4.0)\n",
      "Requirement already satisfied: azure-datalake-store~=0.0.53 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.0.53)\n",
      "Requirement already satisfied: azure-graphrbac~=0.60.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.60.0)\n",
      "Requirement already satisfied: azure-keyvault-administration==4.4.0b2 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.4.0b2)\n",
      "Requirement already satisfied: azure-keyvault-certificates==4.7.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.7.0)\n",
      "Requirement already satisfied: azure-keyvault-keys==4.9.0b3 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.9.0b3)\n",
      "Requirement already satisfied: azure-keyvault-secrets==4.7.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.7.0)\n",
      "Requirement already satisfied: azure-mgmt-advisor==9.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (9.0.0)\n",
      "Requirement already satisfied: azure-mgmt-apimanagement==4.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.0.0)\n",
      "Requirement already satisfied: azure-mgmt-appconfiguration==3.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (3.0.0)\n",
      "Requirement already satisfied: azure-mgmt-appcontainers==2.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.0.0)\n",
      "Requirement already satisfied: azure-mgmt-applicationinsights~=1.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0)\n",
      "Requirement already satisfied: azure-mgmt-authorization~=4.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.0.0)\n",
      "Requirement already satisfied: azure-mgmt-batchai==7.0.0b1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (7.0.0b1)\n",
      "Requirement already satisfied: azure-mgmt-batch~=17.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (17.3.0)\n",
      "Requirement already satisfied: azure-mgmt-billing==6.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (6.0.0)\n",
      "Requirement already satisfied: azure-mgmt-botservice~=2.0.0b3 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.0.0)\n",
      "Requirement already satisfied: azure-mgmt-cdn==12.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (12.0.0)\n",
      "Requirement already satisfied: azure-mgmt-cognitiveservices~=13.5.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (13.5.0)\n",
      "Requirement already satisfied: azure-mgmt-compute~=31.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (31.0.0)\n",
      "Requirement already satisfied: azure-mgmt-containerinstance==10.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.1.0)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry==10.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.3.0)\n",
      "Requirement already satisfied: azure-mgmt-containerservice~=31.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (31.0.0)\n",
      "Requirement already satisfied: azure-mgmt-cosmosdb==9.5.1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (9.5.1)\n",
      "Requirement already satisfied: azure-mgmt-databoxedge~=1.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0)\n",
      "Requirement already satisfied: azure-mgmt-datamigration~=10.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.0.0)\n",
      "Requirement already satisfied: azure-mgmt-devtestlabs~=4.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.0.0)\n",
      "Requirement already satisfied: azure-mgmt-dns~=8.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (8.0.0)\n",
      "Requirement already satisfied: azure-mgmt-eventgrid==10.2.0b2 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.2.0b2)\n",
      "Requirement already satisfied: azure-mgmt-eventhub~=10.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.1.0)\n",
      "Requirement already satisfied: azure-mgmt-extendedlocation==1.0.0b2 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0b2)\n",
      "Requirement already satisfied: azure-mgmt-hdinsight~=9.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (9.0.0)\n",
      "Requirement already satisfied: azure-mgmt-imagebuilder~=1.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.3.0)\n",
      "Requirement already satisfied: azure-mgmt-iotcentral~=10.0.0b1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.0.0b2)\n",
      "Requirement already satisfied: azure-mgmt-iothub==3.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (3.0.0)\n",
      "Requirement already satisfied: azure-mgmt-iothubprovisioningservices==1.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.1.0)\n",
      "Requirement already satisfied: azure-mgmt-keyvault==10.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.3.0)\n",
      "Requirement already satisfied: azure-mgmt-kusto~=0.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.3.0)\n",
      "Requirement already satisfied: azure-mgmt-loganalytics==13.0.0b4 in ./.venv/lib/python3.11/site-packages (from azure-cli) (13.0.0b4)\n",
      "Requirement already satisfied: azure-mgmt-managedservices~=1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0)\n",
      "Requirement already satisfied: azure-mgmt-managementgroups~=1.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0)\n",
      "Requirement already satisfied: azure-mgmt-maps~=2.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.0.0)\n",
      "Requirement already satisfied: azure-mgmt-marketplaceordering==1.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.1.0)\n",
      "Requirement already satisfied: azure-mgmt-media~=9.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (9.0.0)\n",
      "Requirement already satisfied: azure-mgmt-monitor~=5.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (5.0.1)\n",
      "Requirement already satisfied: azure-mgmt-msi~=7.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (7.0.0)\n",
      "Requirement already satisfied: azure-mgmt-netapp~=10.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.1.0)\n",
      "Requirement already satisfied: azure-mgmt-policyinsights==1.1.0b4 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.1.0b4)\n",
      "Requirement already satisfied: azure-mgmt-privatedns~=1.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0)\n",
      "Requirement already satisfied: azure-mgmt-rdbms~=10.2.0b16 in ./.venv/lib/python3.11/site-packages (from azure-cli) (10.2.0b17)\n",
      "Requirement already satisfied: azure-mgmt-recoveryservicesbackup~=9.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (9.1.0)\n",
      "Requirement already satisfied: azure-mgmt-recoveryservices~=3.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (3.0.0)\n",
      "Requirement already satisfied: azure-mgmt-redis~=14.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (14.3.0)\n",
      "Requirement already satisfied: azure-mgmt-redhatopenshift~=1.4.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.4.0)\n",
      "Requirement already satisfied: azure-mgmt-resource==23.1.1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (23.1.1)\n",
      "Requirement already satisfied: azure-mgmt-search~=9.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (9.1.0)\n",
      "Requirement already satisfied: azure-mgmt-security==6.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (6.0.0)\n",
      "Requirement already satisfied: azure-mgmt-servicebus~=8.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (8.2.0)\n",
      "Requirement already satisfied: azure-mgmt-servicefabricmanagedclusters==2.0.0b6 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.0.0b6)\n",
      "Requirement already satisfied: azure-mgmt-servicelinker==1.2.0b2 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.2.0b2)\n",
      "Requirement already satisfied: azure-mgmt-servicefabric~=2.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.1.0)\n",
      "Requirement already satisfied: azure-mgmt-signalr==2.0.0b1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.0.0b1)\n",
      "Requirement already satisfied: azure-mgmt-sqlvirtualmachine==1.0.0b5 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0b5)\n",
      "Requirement already satisfied: azure-mgmt-sql==4.0.0b17 in ./.venv/lib/python3.11/site-packages (from azure-cli) (4.0.0b17)\n",
      "Requirement already satisfied: azure-mgmt-storage==21.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (21.2.0)\n",
      "Requirement already satisfied: azure-mgmt-synapse==2.1.0b5 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.1.0b5)\n",
      "Requirement already satisfied: azure-mgmt-trafficmanager~=1.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.0.0)\n",
      "Requirement already satisfied: azure-mgmt-web==7.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (7.2.0)\n",
      "Requirement already satisfied: azure-monitor-query==1.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.2.0)\n",
      "Requirement already satisfied: azure-multiapi-storage~=1.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.2.0)\n",
      "Requirement already satisfied: azure-storage-common~=1.4 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.4.2)\n",
      "Requirement already satisfied: azure-synapse-accesscontrol~=0.5.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.5.0)\n",
      "Requirement already satisfied: azure-synapse-artifacts~=0.19.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.19.0)\n",
      "Requirement already satisfied: azure-synapse-managedprivateendpoints~=0.4.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.4.0)\n",
      "Requirement already satisfied: azure-synapse-spark~=0.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.2.0)\n",
      "Requirement already satisfied: chardet~=5.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (5.2.0)\n",
      "Requirement already satisfied: colorama~=0.4.4 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.4.6)\n",
      "Requirement already satisfied: fabric~=3.2.2 in ./.venv/lib/python3.11/site-packages (from azure-cli) (3.2.2)\n",
      "Requirement already satisfied: javaproperties~=0.5.1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.5.2)\n",
      "Requirement already satisfied: jsondiff~=2.0.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from azure-cli) (24.1)\n",
      "Requirement already satisfied: pycomposefile>=0.0.29 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.0.31)\n",
      "Requirement already satisfied: PyGithub~=1.38 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.59.1)\n",
      "Requirement already satisfied: PyNaCl~=1.5.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.5.0)\n",
      "Requirement already satisfied: scp~=0.13.2 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.13.6)\n",
      "Requirement already satisfied: semver==2.13.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.13.0)\n",
      "Requirement already satisfied: six>=1.10.0 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.16.0)\n",
      "Requirement already satisfied: sshtunnel~=0.1.4 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.1.5)\n",
      "Requirement already satisfied: tabulate in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.9.0)\n",
      "Requirement already satisfied: urllib3 in ./.venv/lib/python3.11/site-packages (from azure-cli) (2.2.2)\n",
      "Requirement already satisfied: websocket-client~=1.3.1 in ./.venv/lib/python3.11/site-packages (from azure-cli) (1.3.3)\n",
      "Requirement already satisfied: xmltodict~=0.12 in ./.venv/lib/python3.11/site-packages (from azure-cli) (0.13.0)\n",
      "Requirement already satisfied: argcomplete~=3.3.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (3.3.0)\n",
      "Requirement already satisfied: azure-cli-telemetry==1.1.0.* in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (1.1.0)\n",
      "Requirement already satisfied: azure-mgmt-core<2,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (1.4.0)\n",
      "Requirement already satisfied: cryptography in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (43.0.0)\n",
      "Requirement already satisfied: humanfriendly~=10.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (10.0)\n",
      "Requirement already satisfied: jmespath in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (1.0.1)\n",
      "Requirement already satisfied: knack~=0.11.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (0.11.0)\n",
      "Requirement already satisfied: msal-extensions==1.2.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (1.2.0)\n",
      "Requirement already satisfied: msal[broker]==1.30.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (1.30.0)\n",
      "Requirement already satisfied: msrestazure~=0.6.4 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (0.6.4.post1)\n",
      "Requirement already satisfied: paramiko<4.0.0,>=2.0.8 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (3.4.1)\n",
      "Requirement already satisfied: pkginfo>=1.5.0.1 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (1.11.1)\n",
      "Requirement already satisfied: PyJWT>=2.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (2.8.0)\n",
      "Requirement already satisfied: pyopenssl>=17.1.0 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (24.2.1)\n",
      "Requirement already satisfied: requests[socks] in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.9 in ./.venv/lib/python3.11/site-packages (from azure-cli-core==2.63.0->azure-cli) (5.9.8)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.15.0 in ./.venv/lib/python3.11/site-packages (from azure-data-tables==12.4.0->azure-cli) (1.30.2)\n",
      "Requirement already satisfied: msrest>=0.6.21 in ./.venv/lib/python3.11/site-packages (from azure-data-tables==12.4.0->azure-cli) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in ./.venv/lib/python3.11/site-packages (from azure-keyvault-administration==4.4.0b2->azure-cli) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./.venv/lib/python3.11/site-packages (from azure-keyvault-administration==4.4.0b2->azure-cli) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in ./.venv/lib/python3.11/site-packages (from azure-keyvault-administration==4.4.0b2->azure-cli) (4.12.2)\n",
      "Requirement already satisfied: applicationinsights<0.12,>=0.11.1 in ./.venv/lib/python3.11/site-packages (from azure-cli-telemetry==1.1.0.*->azure-cli-core==2.63.0->azure-cli) (0.11.10)\n",
      "Requirement already satisfied: portalocker<3,>=1.6 in ./.venv/lib/python3.11/site-packages (from azure-cli-telemetry==1.1.0.*->azure-cli-core==2.63.0->azure-cli) (2.10.1)\n",
      "Requirement already satisfied: cffi in ./.venv/lib/python3.11/site-packages (from azure-datalake-store~=0.0.53->azure-cli) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.11/site-packages (from azure-multiapi-storage~=1.2.0->azure-cli) (2.9.0.post0)\n",
      "Requirement already satisfied: invoke>=2.0 in ./.venv/lib/python3.11/site-packages (from fabric~=3.2.2->azure-cli) (2.2.0)\n",
      "Requirement already satisfied: decorator>=5 in ./.venv/lib/python3.11/site-packages (from fabric~=3.2.2->azure-cli) (5.1.1)\n",
      "Requirement already satisfied: deprecated>=1.2 in ./.venv/lib/python3.11/site-packages (from fabric~=3.2.2->azure-cli) (1.2.14)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from pycomposefile>=0.0.29->azure-cli) (6.0.2)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi->azure-datalake-store~=0.0.53->azure-cli) (2.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from deprecated>=1.2->fabric~=3.2.2->azure-cli) (1.16.0)\n",
      "Requirement already satisfied: pygments in ./.venv/lib/python3.11/site-packages (from knack~=0.11.0->azure-cli-core==2.63.0->azure-cli) (2.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from msrest>=0.6.21->azure-data-tables==12.4.0->azure-cli) (2024.7.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in ./.venv/lib/python3.11/site-packages (from msrest>=0.6.21->azure-data-tables==12.4.0->azure-cli) (2.0.0)\n",
      "Requirement already satisfied: adal<2.0.0,>=0.6.0 in ./.venv/lib/python3.11/site-packages (from msrestazure~=0.6.4->azure-cli-core==2.63.0->azure-cli) (1.2.7)\n",
      "Requirement already satisfied: bcrypt>=3.2 in ./.venv/lib/python3.11/site-packages (from paramiko<4.0.0,>=2.0.8->azure-cli-core==2.63.0->azure-cli) (4.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests[socks]->azure-cli-core==2.63.0->azure-cli) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests[socks]->azure-cli-core==2.63.0->azure-cli) (3.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./.venv/lib/python3.11/site-packages (from requests[socks]->azure-cli-core==2.63.0->azure-cli) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-data-tables==12.4.0->azure-cli) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cli pandas openai fastparquet pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from azure.identity import AzureCliCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing the merged parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"merged_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"remove_type\"] == \"excel_error\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"No HTML Tags\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove articles with 'No HTML Tags' from the 'remove_type' column\n",
    "df = df.loc[df[\"remove_type\"] != \"No HTML Tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"No HTML Tags\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"No Extracted Content\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with 'No Extracted Content' from 'remove_type' column\n",
    "df = df[df[\"remove_type\"] != \"No Extracted Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"No Extracted Content\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"NaN\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with 'NaN' from 'remove_type' column\n",
    "df = df[df[\"remove_type\"] != \"NaN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"NaN\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"Multilingual\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Multilingual' from 'remove_type' column\n",
    "df = df[df[\"remove_type\"] != \"Multilingual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"Multilingual\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"id\"].isin([1444496, 1445629, 1443608, 1435183, 1435335, 1434652])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicated articles with the 'id' = \"1445629\", \"1443608\", \"1435183\", \"1435335\", \"1434652\".\n",
    "df = df[~df[\"id\"].isin([1444496, 1445629, 1443608, 1435183, 1435335, 1434652])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"id\"].isin([1444496, 1445629, 1443608, 1435183, 1435335, 1434652])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"id\"].isin([1497409, 1469472])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"remove_type\"] == \"Duplicated Content\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the 'Duplicated Content' from 'remove_type' column and only keep the articles with the 'id' = \"1497409\", \"1469472\".\n",
    "df = df[(df[\"remove_type\"] != \"Duplicated Content\") | (df[\"id\"].isin([1497409, 1469472]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new parquet file with the name 'merged_data_rag.parquet'\n",
    "df.to_parquet(\"merged_data_rag.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the data in the 'content_category' column\n",
    "df[\"content_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new parquet file with selected articles for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted articles [1445517] and saved to /Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/index.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load the original Parquet file\n",
    "input_file = \"/Users/Richmond/Desktop/syn/healthhub-content-optimization/content-optimization/data/03_primary/merged_data.parquet/merged_data_rag.parquet\"\n",
    "df = pd.read_parquet(input_file)\n",
    "\n",
    "# Filter the DataFrame to get the rows with specific article IDs\n",
    "article_id_to_extract = [1445517]\n",
    "filtered_df = df[df[\"id\"].isin(article_id_to_extract)]\n",
    "\n",
    "# Ensure the data_processing directory exists\n",
    "output_dir = \"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the filtered DataFrame as a new Parquet file\n",
    "output_file = os.path.join(output_dir, \"index.parquet\")\n",
    "filtered_df.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"Extracted articles {article_id_to_extract} and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the pre-processed parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/index.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content_name</th>\n",
       "      <th>title</th>\n",
       "      <th>article_category_names</th>\n",
       "      <th>cover_image_url</th>\n",
       "      <th>full_url</th>\n",
       "      <th>full_url2</th>\n",
       "      <th>friendly_url</th>\n",
       "      <th>category_description</th>\n",
       "      <th>content_body</th>\n",
       "      <th>...</th>\n",
       "      <th>extracted_content_body</th>\n",
       "      <th>l1_mappings</th>\n",
       "      <th>l2_mappings</th>\n",
       "      <th>page_views</th>\n",
       "      <th>engagement_rate</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>exit_rate</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>percentage_total_views</th>\n",
       "      <th>cumulative_percentage_total_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1445517</td>\n",
       "      <td>Healthy Ways to Manage Your Weight</td>\n",
       "      <td>Healthy Ways to Manage Your Weight</td>\n",
       "      <td>Exercise and Fitness,Food and Nutrition,</td>\n",
       "      <td>https://ch-api.healthhub.sg/api/public/content...</td>\n",
       "      <td>https://www.healthhub.sg/live-healthy/Manage W...</td>\n",
       "      <td>www.healthhub.sg/live-healthy/Manage Weight He...</td>\n",
       "      <td>Manage Weight Healthily</td>\n",
       "      <td>Finding it a struggle to manage your weight? U...</td>\n",
       "      <td>b'&lt;div class=\"ExternalClassA1CC8F76D57D4D87888...</td>\n",
       "      <td>...</td>\n",
       "      <td>Weight management - it's easier than you think...</td>\n",
       "      <td>Well-being &amp; Lifestyle</td>\n",
       "      <td>Exercise and Fitness | Food, Diet and Nutrition</td>\n",
       "      <td>1455</td>\n",
       "      <td>0.972685</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.107216</td>\n",
       "      <td>0.271478</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.789989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        content_name  \\\n",
       "0  1445517  Healthy Ways to Manage Your Weight   \n",
       "\n",
       "                                title  \\\n",
       "0  Healthy Ways to Manage Your Weight   \n",
       "\n",
       "                     article_category_names  \\\n",
       "0  Exercise and Fitness,Food and Nutrition,   \n",
       "\n",
       "                                     cover_image_url  \\\n",
       "0  https://ch-api.healthhub.sg/api/public/content...   \n",
       "\n",
       "                                            full_url  \\\n",
       "0  https://www.healthhub.sg/live-healthy/Manage W...   \n",
       "\n",
       "                                           full_url2             friendly_url  \\\n",
       "0  www.healthhub.sg/live-healthy/Manage Weight He...  Manage Weight Healthily   \n",
       "\n",
       "                                category_description  \\\n",
       "0  Finding it a struggle to manage your weight? U...   \n",
       "\n",
       "                                        content_body  ...  \\\n",
       "0  b'<div class=\"ExternalClassA1CC8F76D57D4D87888...  ...   \n",
       "\n",
       "                              extracted_content_body             l1_mappings  \\\n",
       "0  Weight management - it's easier than you think...  Well-being & Lifestyle   \n",
       "\n",
       "                                       l2_mappings page_views engagement_rate  \\\n",
       "0  Exercise and Fitness | Food, Diet and Nutrition       1455        0.972685   \n",
       "\n",
       "   bounce_rate  exit_rate  scroll_percentage percentage_total_views  \\\n",
       "0     0.027315   0.107216           0.271478               0.000625   \n",
       "\n",
       "   cumulative_percentage_total_views  \n",
       "0                           0.789989  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass the table content into GPT-4o and create a new parquet with the new column \"processed_table_content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(html_content: str) -> str:\n",
    "    azure_credential = AzureCliCredential()\n",
    "    token_provider = get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "    openai_client = AzureOpenAI(\n",
    "        api_version=\"2024-06-01\",\n",
    "        azure_endpoint=\"https://apim-jisfkas7teqvm.azure-api.net\",\n",
    "        azure_ad_token_provider=token_provider,\n",
    "    )\n",
    "\n",
    "    # Updated prompt to discourage repetition\n",
    "    prompt = \"\"\"\n",
    "    Below is the given full article HTML. Extract the **content of the tables** and their **relevant descriptions** that help understand the tables. \n",
    "    Ensure:\n",
    "    - Retain only essential markdown formatting, such as:\n",
    "        - **Bold** for headers or important table titles.\n",
    "        - **Tables** formatted using markdown syntax (e.g., `| Header 1 | Header 2 |`).\n",
    "    - Avoid unnecessary dashes, bullet points, and extraneous markdown symbols.\n",
    "    - Remove all other HTML tags.\n",
    "    - Keep the output concise, accurate, and under 4,000 words. If it exceeds 4,000 words, prioritize summarization.\n",
    "    - Output the response as a readable markdown string.\n",
    "\n",
    "    {html_content}\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the messages for the API call\n",
    "    query_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant specialized in extracting structured content from HTML.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt.format(html_content=html_content)},\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        messages=query_messages,\n",
    "        model=\"chat\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=4096,\n",
    "        n=1,\n",
    "        seed=1234,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Extract and process HTML tables\n",
    "\n",
    "\n",
    "def process_html_tables(row):\n",
    "    if row[\"has_table\"]:\n",
    "        return ask(row[\"content_body\"])\n",
    "    return None\n",
    "\n",
    "\n",
    "# Apply processing to the DataFrame with tqdm for progress tracking\n",
    "tqdm.pandas()  # Enable progress bar for DataFrame operations\n",
    "df_filtered[\"processed_table_content\"] = df_filtered.progress_apply(process_html_tables, axis=1)\n",
    "\n",
    "# Save to a new Parquet file\n",
    "output_file = \"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/new_index.parquet\"\n",
    "df.to_parquet(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the post-processed parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/new_index.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"/Users/Richmond/Desktop/syn/azure-conversational-assistant/data_processing/new_index.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the top k table length after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xd/bj3151rn7cv92frd9tzmsg4r0000gp/T/ipykernel_32558/669495784.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1_filtered['content_length'] = df1_filtered['processed_table_content'].apply(len)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_table_content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>id</th>\n",
       "      <th>friendly_url</th>\n",
       "      <th>content_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>**Recommended Dietary Allowances for Normal He...</td>\n",
       "      <td>13092</td>\n",
       "      <td>1444820</td>\n",
       "      <td>recommended_dietary_allowances</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>**Food and Water Borne Diseases**\\n\\nHere are ...</td>\n",
       "      <td>12028</td>\n",
       "      <td>1445538</td>\n",
       "      <td>travellersurvivalguide</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>**How Much Protein do you Need?**\\n\\n| Age Ran...</td>\n",
       "      <td>10556</td>\n",
       "      <td>1445282</td>\n",
       "      <td>seniors-need-more-protein</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>**Symptoms and Reasons for Feeling Worse After...</td>\n",
       "      <td>10274</td>\n",
       "      <td>1434716</td>\n",
       "      <td>IQuit</td>\n",
       "      <td>programs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>**A. Insulin vial (small cylindrical glass con...</td>\n",
       "      <td>9849</td>\n",
       "      <td>1440453</td>\n",
       "      <td>Insulin-Injection-Technique</td>\n",
       "      <td>medications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>**Eat Healthily and Stay Active**\\n\\nHelping y...</td>\n",
       "      <td>9837</td>\n",
       "      <td>1442929</td>\n",
       "      <td>growing-kid-raising-healthy-kids</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td># Admissions and Outpatient Attendances\\n\\n**H...</td>\n",
       "      <td>9548</td>\n",
       "      <td>1437940</td>\n",
       "      <td>admissions-and-outpatient-attendances</td>\n",
       "      <td>health-statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>**Nutritional Requirements for Toddlers after ...</td>\n",
       "      <td>9538</td>\n",
       "      <td>1445172</td>\n",
       "      <td>nutrition-for-toddlers-25-36-months-old</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>**About Respite Care for Caregivers**\\n\\nCareg...</td>\n",
       "      <td>8562</td>\n",
       "      <td>1437970</td>\n",
       "      <td>respite_care</td>\n",
       "      <td>medical-care-and-facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>**Meeting nutritional needs of kids and teenag...</td>\n",
       "      <td>8396</td>\n",
       "      <td>1445673</td>\n",
       "      <td>A Healthy Food Foundation - for Kids and Teens</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>**Overcoming Barriers to Exercise**\\n\\n| Barri...</td>\n",
       "      <td>8390</td>\n",
       "      <td>1445346</td>\n",
       "      <td>manage_weight_healthy_way</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>**The Right Environment for Brain Development*...</td>\n",
       "      <td>8334</td>\n",
       "      <td>1445669</td>\n",
       "      <td>babysfirstyearbrain</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>**Essential Nutrients for Pregnancy**\\n\\n**Tab...</td>\n",
       "      <td>7765</td>\n",
       "      <td>1446016</td>\n",
       "      <td>pregnancy-nutrition-during-pregnancy-eating-ri...</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>**Myth #1: I am unlikely to face fertility hea...</td>\n",
       "      <td>7586</td>\n",
       "      <td>1445311</td>\n",
       "      <td>debunking-5-myths-of-fertility-health</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>**Workplace Conflicts and Mental Wellness**\\n\\...</td>\n",
       "      <td>7576</td>\n",
       "      <td>1444303</td>\n",
       "      <td>thrive-not-just-survive-at-the-workplace</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>**Medication and Side-effects**\\n\\n| **Medicat...</td>\n",
       "      <td>7278</td>\n",
       "      <td>1439975</td>\n",
       "      <td>Antifungals-Oral</td>\n",
       "      <td>medications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>**Sleep and Diabetes Care**\\n\\nIf you have [di...</td>\n",
       "      <td>7252</td>\n",
       "      <td>1443392</td>\n",
       "      <td>dont-lose-sleep-over-diabetes</td>\n",
       "      <td>live-healthy-articles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                processed_table_content  content_length  \\\n",
       "378   **Recommended Dietary Allowances for Normal He...           13092   \n",
       "950   **Food and Water Borne Diseases**\\n\\nHere are ...           12028   \n",
       "369   **How Much Protein do you Need?**\\n\\n| Age Ran...           10556   \n",
       "2525  **Symptoms and Reasons for Feeling Worse After...           10274   \n",
       "1705  **A. Insulin vial (small cylindrical glass con...            9849   \n",
       "773   **Eat Healthily and Stay Active**\\n\\nHelping y...            9837   \n",
       "357   # Admissions and Outpatient Attendances\\n\\n**H...            9548   \n",
       "553   **Nutritional Requirements for Toddlers after ...            9538   \n",
       "1545  **About Respite Care for Caregivers**\\n\\nCareg...            8562   \n",
       "1519  **Meeting nutritional needs of kids and teenag...            8396   \n",
       "1073  **Overcoming Barriers to Exercise**\\n\\n| Barri...            8390   \n",
       "724   **The Right Environment for Brain Development*...            8334   \n",
       "372   **Essential Nutrients for Pregnancy**\\n\\n**Tab...            7765   \n",
       "1092  **Myth #1: I am unlikely to face fertility hea...            7586   \n",
       "981   **Workplace Conflicts and Mental Wellness**\\n\\...            7576   \n",
       "1700  **Medication and Side-effects**\\n\\n| **Medicat...            7278   \n",
       "809   **Sleep and Diabetes Care**\\n\\nIf you have [di...            7252   \n",
       "\n",
       "           id                                       friendly_url  \\\n",
       "378   1444820                     recommended_dietary_allowances   \n",
       "950   1445538                             travellersurvivalguide   \n",
       "369   1445282                          seniors-need-more-protein   \n",
       "2525  1434716                                              IQuit   \n",
       "1705  1440453                        Insulin-Injection-Technique   \n",
       "773   1442929                   growing-kid-raising-healthy-kids   \n",
       "357   1437940              admissions-and-outpatient-attendances   \n",
       "553   1445172            nutrition-for-toddlers-25-36-months-old   \n",
       "1545  1437970                                       respite_care   \n",
       "1519  1445673     A Healthy Food Foundation - for Kids and Teens   \n",
       "1073  1445346                          manage_weight_healthy_way   \n",
       "724   1445669                                babysfirstyearbrain   \n",
       "372   1446016  pregnancy-nutrition-during-pregnancy-eating-ri...   \n",
       "1092  1445311              debunking-5-myths-of-fertility-health   \n",
       "981   1444303           thrive-not-just-survive-at-the-workplace   \n",
       "1700  1439975                                   Antifungals-Oral   \n",
       "809   1443392                      dont-lose-sleep-over-diabetes   \n",
       "\n",
       "                 content_category  \n",
       "378         live-healthy-articles  \n",
       "950         live-healthy-articles  \n",
       "369         live-healthy-articles  \n",
       "2525                     programs  \n",
       "1705                  medications  \n",
       "773         live-healthy-articles  \n",
       "357             health-statistics  \n",
       "553         live-healthy-articles  \n",
       "1545  medical-care-and-facilities  \n",
       "1519        live-healthy-articles  \n",
       "1073        live-healthy-articles  \n",
       "724         live-healthy-articles  \n",
       "372         live-healthy-articles  \n",
       "1092        live-healthy-articles  \n",
       "981         live-healthy-articles  \n",
       "1700                  medications  \n",
       "809         live-healthy-articles  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure 'processed_table_content' column does not contain None values\n",
    "df1_filtered = df1[df1[\"processed_table_content\"].notnull() & df1[\"has_table\"]]\n",
    "\n",
    "# Find the lengths of each string in the \"processed_table_content\" column\n",
    "df1_filtered[\"content_length\"] = df1_filtered[\"processed_table_content\"].apply(len)\n",
    "\n",
    "# Sort the dataframe by content length in descending order and get the top 17\n",
    "top_30_longest = df1_filtered.nlargest(17, \"content_length\")\n",
    "\n",
    "# Display the relevant columns for the top 17 entries\n",
    "top_30_longest[[\"processed_table_content\", \"content_length\", \"id\", \"friendly_url\", \"content_category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content has been written to processed_table_content_1440254.txt\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe to find the row with id 1440254\n",
    "content = df1[df1[\"id\"] == 1445517][\"processed_table_content\"].values[0]\n",
    "\n",
    "# Write the content to a text file\n",
    "with open(\"processed_table_content_1440254.txt\", \"w\") as file:\n",
    "    file.write(content)\n",
    "\n",
    "print(\"Content has been written to processed_table_content_1440254.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the top k articles post-processed \"processed_table_content\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Filter the DataFrame by the specific IDs\n",
    "# filtered_df = df1[df1['id'].isin([1439448, 1445517])]\n",
    "\n",
    "# # Step 3: Extract the 'processed_table_content' column for the selected rows\n",
    "# content_1439448 = filtered_df[filtered_df['id'] == 1439448]['processed_table_content'].values[0]\n",
    "# content_1445517 = filtered_df[filtered_df['id'] == 1445517]['processed_table_content'].values[0]\n",
    "\n",
    "# # Step 4: Write the content to a .txt file\n",
    "# with open(\"processed_content_1439448.txt\", \"w\") as file1:\n",
    "#     file1.write(content_1439448)\n",
    "\n",
    "# with open(\"processed_content_1445517.txt\", \"w\") as file2:\n",
    "#     file2.write(content_1445517)\n",
    "\n",
    "# print(\"Files saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually curate the content to ensure the quality of the data for ingestion into the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Define the new content for each ID\n",
    "# new_content_1439448 = \"\"\"\n",
    "# **Week 3 of the pack:**\n",
    "\n",
    "# | No missed tablets in the last 7 days | Take the missed tablet as soon as remembered, even if it means taking 2 tablets at the same time. Continue to take your tablets at your usual time and start the next pack right away without the 7-day tablet free period or 7-day white (inactive) tablets i.e. no gap should be left between packs. Your menses may not come until the next pack is finished, but there is no need to worry. However, if your menses do not occur after the next pack is finished, you should take a pregnancy test to make sure you are not pregnant. OR Stop taking medication from the current pack for 7 days (7-day tablet-free period). A withdrawal bleed (menses) usually occurs and then start a next pack after 7 days. |\n",
    "# \"\"\"\n",
    "\n",
    "# new_content_1445517 = \"\"\"\n",
    "# **Suggestions for Overcoming Physical Activity Barriers**\n",
    "\n",
    "# | Lack of time | Monitor your daily activities for one week. Identify available time slots where you can get at least 10 minutes of aerobic type physical activity. Add physical activity to your daily routine. Walk or ride your bicycle to work or to the shops, and organise your daily activities around physical activity. E.g. walk the dog, exercise while you watch TV, park farther away from your destination. Select activities requiring minimal time, such as walking, jogging or stair climbing. |\n",
    "# \"\"\"\n",
    "\n",
    "# # Step 3: Update the 'processed_table_content' for the given IDs\n",
    "# df.loc[df1['id'] == 1439448, 'processed_table_content'] = new_content_1439448\n",
    "# df.loc[df1['id'] == 1445517, 'processed_table_content'] = new_content_1445517\n",
    "\n",
    "# # Step 4: Save the updated DataFrame to a new Parquet file\n",
    "# df1.to_parquet(\"data_processing/new_index.parquet\")\n",
    "\n",
    "# print(\"Updated content and saved to Parquet file successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract out the \"content_body\" as a .txt file to verify extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw content body for article 1435005 saved to ./data_processing/raw_content_body/raw_article_1435005.txt\n",
      "Raw content body for article 1434994 saved to ./data_processing/raw_content_body/raw_article_1434994.txt\n",
      "Raw content body for article 1435059 saved to ./data_processing/raw_content_body/raw_article_1435059.txt\n",
      "Raw content body for article 1434998 saved to ./data_processing/raw_content_body/raw_article_1434998.txt\n",
      "Raw content body for article 1464135 saved to ./data_processing/raw_content_body/raw_article_1464135.txt\n",
      "Raw content body for article 1445643 saved to ./data_processing/raw_content_body/raw_article_1445643.txt\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where 'has_table' is True\n",
    "filtered_df1 = df1[df1[\"has_table\"]]\n",
    "\n",
    "# Ensure the raw_content_body directory exists\n",
    "raw_content_dir = \"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/html_tables_cleaning\"\n",
    "os.makedirs(raw_content_dir, exist_ok=True)\n",
    "\n",
    "# Process each article ID\n",
    "for article_id in filtered_df1[\"id\"].unique():\n",
    "    # Filter the DataFrame for the current article ID\n",
    "    article_df = filtered_df1[filtered_df1[\"id\"] == article_id]\n",
    "\n",
    "    # Extract the 'content_body' column\n",
    "    processed_content = article_df[\"content_body\"].tolist()\n",
    "\n",
    "    # Define the output file path\n",
    "    output_txt_file = f\"{raw_content_dir}/raw_article_{article_id}.txt\"\n",
    "\n",
    "    # Write the content to a text file\n",
    "    with open(output_txt_file, \"w\") as file:\n",
    "        for content in processed_content:\n",
    "            # Check if content is in bytes and decode if necessary\n",
    "            if isinstance(content, bytes):\n",
    "                content = content.decode(\"utf-8\")\n",
    "            file.write(content + \"\\n\")  # Write each entry on a new line\n",
    "\n",
    "    print(f\"Raw content body for article {article_id} saved to {output_txt_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract out the \"processed_table_content\" as a .txt file to verify extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed table content for article 1464135 saved to ./data_processing/processed_table_content/processed_table_content_1464135.txt\n",
      "Processed table content for article 1445643 saved to ./data_processing/processed_table_content/processed_table_content_1445643.txt\n",
      "Processed table content for article 1434994 saved to ./data_processing/processed_table_content/processed_table_content_1434994.txt\n",
      "Processed table content for article 1435005 saved to ./data_processing/processed_table_content/processed_table_content_1435005.txt\n",
      "Processed table content for article 1434998 saved to ./data_processing/processed_table_content/processed_table_content_1434998.txt\n",
      "Processed table content for article 1435059 saved to ./data_processing/processed_table_content/processed_table_content_1435059.txt\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where 'has_table' is True\n",
    "filtered_df = df1[df1[\"has_table\"]]\n",
    "\n",
    "# Ensure the raw_content_body directory exists\n",
    "processed_content_dir = \"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/html_tables_cleaning\"\n",
    "os.makedirs(processed_content_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each article ID to process\n",
    "for article_id in article_id_to_extract:\n",
    "    # Filter the DataFrame for the specific article ID\n",
    "    article_df = filtered_df[filtered_df[\"id\"] == article_id]\n",
    "\n",
    "    if not article_df.empty:\n",
    "        # Extract the 'processed_table_content' column\n",
    "        processed_content = article_df[\"processed_table_content\"].astype(str).tolist()\n",
    "\n",
    "        # Define the output file path\n",
    "        output_txt_file = f\"{processed_content_dir}/processed_table_content_{article_id}.txt\"\n",
    "\n",
    "        # Write the content to a text file\n",
    "        with open(output_txt_file, \"w\") as file:\n",
    "            for content in processed_content:\n",
    "                file.write(content + \"\\n\")  # Write each entry on a new line\n",
    "\n",
    "        print(f\"Processed table content for article {article_id} saved to {output_txt_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that processed_table_content is added as the last column of the new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame:\n",
      "id\n",
      "content_name\n",
      "title\n",
      "article_category_names\n",
      "cover_image_url\n",
      "full_url\n",
      "full_url2\n",
      "friendly_url\n",
      "category_description\n",
      "content_body\n",
      "keywords\n",
      "feature_title\n",
      "pr_name\n",
      "alternate_image_text\n",
      "date_modified\n",
      "number_of_views\n",
      "last_month_view_count\n",
      "last_two_months_view\n",
      "page_views\n",
      "engagement_rate\n",
      "bounce_rate\n",
      "exit_rate\n",
      "scroll_percentage\n",
      "percentage_total_views\n",
      "cumulative_percentage_total_views\n",
      "content_category\n",
      "to_remove\n",
      "remove_type\n",
      "has_table\n",
      "has_image\n",
      "related_sections\n",
      "extracted_tables\n",
      "extracted_raw_html_tables\n",
      "extracted_links\n",
      "extracted_headers\n",
      "extracted_images\n",
      "extracted_content_body\n",
      "l1_mappings\n",
      "l2_mappings\n",
      "processed_table_content\n"
     ]
    }
   ],
   "source": [
    "# Print all columns of the DataFrame\n",
    "print(\"Columns in DataFrame:\")\n",
    "for column in df1.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the columns to extract for article content and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract1 = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"cover_image_url\",\n",
    "    \"full_url\",\n",
    "    \"extracted_content_body\",\n",
    "    \"content_category\",\n",
    "    \"category_description\",\n",
    "    \"has_table\",  # Add this column to filter rows with tables after extracting the content\n",
    "]\n",
    "\n",
    "columns_to_extract2 = [\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"cover_image_url\",\n",
    "    \"full_url\",\n",
    "    \"processed_table_content\",\n",
    "    \"content_category\",\n",
    "    \"category_description\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the article count with tables and output their \"full_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with 'has_table' == True: 6\n",
      "Articles with tables:\n",
      "        id  \\\n",
      "0  1435005   \n",
      "1  1434994   \n",
      "2  1435059   \n",
      "3  1434998   \n",
      "6  1464135   \n",
      "7  1445643   \n",
      "\n",
      "                                                                                 full_url  \n",
      "0             https://www.healthhub.sg/a-z/costs-and-financing/enhancement_active_seniors  \n",
      "1  https://www.healthhub.sg/a-z/costs-and-financing/subsidies_intermediate_long_term_care  \n",
      "2                            https://www.healthhub.sg/a-z/costs-and-financing/eldershield  \n",
      "3                https://www.healthhub.sg/a-z/costs-and-financing/assistance_scheme_IDAPE  \n",
      "6           https://www.healthhub.sg/a-z/diseases-and-conditions/stroke_returning_to_work  \n",
      "7                                https://www.healthhub.sg/live-healthy/gettingsupportstis  \n"
     ]
    }
   ],
   "source": [
    "# List of article IDs to check\n",
    "article_ids = [\n",
    "    1442739,\n",
    "    1445332,\n",
    "    1439757,\n",
    "    1439210,\n",
    "    1443217,\n",
    "    1435054,\n",
    "    1437631,\n",
    "    1434620,\n",
    "    1444553,\n",
    "    1445932,\n",
    "    1437772,\n",
    "    1435185,\n",
    "    1435017,\n",
    "    1464135,\n",
    "    1445643,\n",
    "    1434994,\n",
    "    1435005,\n",
    "    1434998,\n",
    "    1435059,\n",
    "]\n",
    "\n",
    "# Filter the DataFrame for the rows with the specified article IDs\n",
    "filtered_df = df[df[\"id\"].isin(article_ids)]\n",
    "\n",
    "# Check which rows have 'has_table' == True\n",
    "articles_with_tables = filtered_df[filtered_df[\"has_table\"]]\n",
    "\n",
    "# Count of articles with tables\n",
    "has_table_count = articles_with_tables.shape[0]\n",
    "\n",
    "# Extract article IDs and full URLs\n",
    "article_info = articles_with_tables[[\"id\", \"full_url\"]]\n",
    "\n",
    "# Adjust display settings for full URL visibility\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Print the count and article info\n",
    "print(f\"Number of articles with 'has_table' == True: {has_table_count}\")\n",
    "print(\"Articles with tables:\")\n",
    "print(article_info)\n",
    "\n",
    "# Optionally reset display settings if needed\n",
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific articles extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved at: ./data_processing/processed_articles/1442739_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1445332_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1439757_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1439210_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1443217_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1435054_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1437631_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1434620_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1444553_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1445932_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1437772_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1435185_content.json\n",
      "JSON file saved at: ./data_processing/processed_articles/1435017_content.json\n",
      "JSON files saved at: ./data_processing/processed_articles/1464135_content.json and ./data_processing/processed_articles/1464135_table.json\n",
      "JSON files saved at: ./data_processing/processed_articles/1445643_content.json and ./data_processing/processed_articles/1445643_table.json\n",
      "JSON files saved at: ./data_processing/processed_articles/1434994_content.json and ./data_processing/processed_articles/1434994_table.json\n",
      "JSON files saved at: ./data_processing/processed_articles/1435005_content.json and ./data_processing/processed_articles/1435005_table.json\n",
      "JSON files saved at: ./data_processing/processed_articles/1434998_content.json and ./data_processing/processed_articles/1434998_table.json\n",
      "JSON files saved at: ./data_processing/processed_articles/1435059_content.json and ./data_processing/processed_articles/1435059_table.json\n"
     ]
    }
   ],
   "source": [
    "# List of article IDs to extract\n",
    "article_ids = [\n",
    "    1442739,\n",
    "    1445332,\n",
    "    1439757,\n",
    "    1439210,\n",
    "    1443217,\n",
    "    1435054,\n",
    "    1437631,\n",
    "    1434620,\n",
    "    1444553,\n",
    "    1445932,\n",
    "    1437772,\n",
    "    1435185,\n",
    "    1435017,\n",
    "    1464135,\n",
    "    1445643,\n",
    "    1434994,\n",
    "    1435005,\n",
    "    1434998,\n",
    "    1435059,\n",
    "]\n",
    "\n",
    "# Specify the directory\n",
    "output_directory = \"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/processed_articles\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through each article ID in the list\n",
    "for article_id in article_ids:\n",
    "    # Extract the row based on the article ID\n",
    "    row = df1[df1[\"id\"] == article_id]\n",
    "\n",
    "    # Check if row is empty\n",
    "    if row.empty:\n",
    "        print(f\"Article ID {article_id} not found in the DataFrame.\")\n",
    "        continue\n",
    "\n",
    "    row_number = row.index[0]  # Get the index of the row\n",
    "\n",
    "    # Extract the specified columns for the given row\n",
    "    extracted_row1 = df1.loc[row_number, columns_to_extract1]\n",
    "\n",
    "    # Check if the row has a table\n",
    "    has_table = extracted_row1[\"has_table\"]\n",
    "\n",
    "    # Convert the extracted row to a dictionary and remove 'has_table'\n",
    "    extracted_data1 = extracted_row1.drop(\"has_table\").to_dict()\n",
    "\n",
    "    # Rename the key to \"content\"\n",
    "    extracted_data1[\"content\"] = str(extracted_data1.pop(\"extracted_content_body\"))\n",
    "\n",
    "    # Convert specific fields to strings and append the desired suffix\n",
    "    extracted_data1[\"id\"] = str(article_id) + \"_content\"\n",
    "\n",
    "    # Wrap the dictionary in a list to match the desired format\n",
    "    extracted_data_list1 = [extracted_data1]\n",
    "\n",
    "    # Create unique file name using the article ID\n",
    "    output_filename1 = f\"{article_id}_content.json\"\n",
    "\n",
    "    # Define output path\n",
    "    output_path1 = os.path.join(output_directory, output_filename1)\n",
    "\n",
    "    # Export the extracted content body to a JSON file\n",
    "    with open(output_path1, \"w\") as json_file:\n",
    "        json.dump(extracted_data_list1, json_file, indent=4)\n",
    "\n",
    "    # If there is a table, extract and save it as well\n",
    "    if has_table:\n",
    "        extracted_row2 = df1.loc[row_number, columns_to_extract2]\n",
    "        extracted_data2 = extracted_row2.to_dict()\n",
    "        extracted_data2[\"content\"] = str(extracted_data2.pop(\"processed_table_content\"))\n",
    "        extracted_data2[\"id\"] = str(article_id) + \"_table\"\n",
    "\n",
    "        # Wrap the dictionary in a list to match the desired format\n",
    "        extracted_data_list2 = [extracted_data2]\n",
    "\n",
    "        # Create unique file name for the raw HTML tables\n",
    "        output_filename2 = f\"{article_id}_table.json\"\n",
    "        output_path2 = os.path.join(output_directory, output_filename2)\n",
    "\n",
    "        # Export the extracted raw HTML tables to a JSON file\n",
    "        with open(output_path2, \"w\") as json_file:\n",
    "            json.dump(extracted_data_list2, json_file, indent=4)\n",
    "\n",
    "        # Confirm the files were saved\n",
    "        print(f\"JSON files saved at: {output_path1} and {output_path2}\")\n",
    "    else:\n",
    "        # Confirm the content body file was saved\n",
    "        print(f\"JSON file saved at: {output_path1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all .json files from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_json_files(directory):\n",
    "    \"\"\"\n",
    "    Removes all .json files from the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The path to the directory where .json files are to be removed.\n",
    "    \"\"\"\n",
    "    # Create the search pattern for .json files\n",
    "    search_pattern = os.path.join(directory, \"*.json\")\n",
    "\n",
    "    # Get a list of all .json files in the directory\n",
    "    json_files = glob.glob(search_pattern)\n",
    "\n",
    "    # Remove each .json file\n",
    "    for file in json_files:\n",
    "        os.remove(file)\n",
    "        print(f\"Removed file: {file}\")\n",
    "\n",
    "\n",
    "# Specify the directory where .json files are located\n",
    "output_directory = \"/Users/Richmond/Desktop/syn/HealthierMe2.0/json_test/processed_articles\"\n",
    "\n",
    "# Call the function to remove .json files\n",
    "remove_json_files(output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
